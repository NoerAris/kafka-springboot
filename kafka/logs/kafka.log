2020-06-05 11:29:37,736 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 1608 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 11:29:37,740 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 11:29:38,597 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 11:29:38,603 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 11:29:38,604 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 11:29:38,672 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 11:29:38,672 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 11:29:38,672 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 895 ms
2020-06-05 11:29:38,864 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 11:29:38,873 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 11:29:38,914 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 3 mappings in 'requestMappingHandlerMapping'
2020-06-05 11:29:38,950 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 11:29:38,961 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 11:29:39,090 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 11:29:39,142 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 11:29:39,143 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 11:29:39,144 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591331379141
2020-06-05 11:29:39,146 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 11:29:39,148 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 11:29:39,169 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 11:29:39,179 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.786 seconds (JVM running for 2.705)
2020-06-05 11:29:39,458 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 11:29:39,460 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 11:29:39,462 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:29:39,472 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 11:29:39,472 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:29:39,478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 30: {consumer-group_id-1-dd88deaa-7c96-4f1c-95a4-56a584b9a2a3=Assignment(partitions=[foo.t-0])}
2020-06-05 11:29:39,483 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 30
2020-06-05 11:29:39,486 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 11:29:39,494 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=8, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 11:29:39,495 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 11:30:03,189 INFO  [http-nio-7013-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 11:30:03,189 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 11:30:03,189 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 11:30:03,194 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 11:30:03,194 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 5 ms
2020-06-05 11:30:03,200 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/publish?message=pompom%20cuk%20dancuk%20mbot", parameters={masked}
2020-06-05 11:30:03,203 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessageToKafkaTopic(String)
2020-06-05 11:30:03,216 INFO  [http-nio-7013-exec-2] com.spring.kafka.controller.KafkaController : send messege : pompom cuk dancuk mbot
2020-06-05 11:30:03,216 INFO  [http-nio-7013-exec-2] com.spring.kafka.service.Producer : sending message='pompom cuk dancuk mbot' to topic='foo.t'
2020-06-05 11:30:03,220 INFO  [http-nio-7013-exec-2] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 11:30:03,235 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 11:30:03,235 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 11:30:03,235 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591331403235
2020-06-05 11:30:03,242 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 11:30:03,271 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consumed message='pompom cuk dancuk mbot'
2020-06-05 11:30:03,273 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 11:30:03,273 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 11:30:03,274 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 11:32:39,973 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 3940 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 11:32:39,977 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 11:32:40,775 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 11:32:40,781 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 11:32:40,782 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 11:32:40,843 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 11:32:40,844 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 11:32:40,844 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 831 ms
2020-06-05 11:32:41,016 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 11:32:41,024 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 11:32:41,062 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 3 mappings in 'requestMappingHandlerMapping'
2020-06-05 11:32:41,084 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 11:32:41,090 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 11:32:41,217 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 11:32:41,274 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 11:32:41,275 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 11:32:41,276 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591331561273
2020-06-05 11:32:41,278 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 11:32:41,280 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 11:32:41,297 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 11:32:41,306 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.667 seconds (JVM running for 2.575)
2020-06-05 11:32:41,557 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 11:32:41,559 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 11:32:41,561 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:32:41,569 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 11:32:41,569 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:32:46,528 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 31: {consumer-group_id-1-34e5f8b1-914a-4632-af6a-e7cee2284c83=Assignment(partitions=[foo.t-0])}
2020-06-05 11:32:46,534 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 31
2020-06-05 11:32:46,538 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 11:32:46,546 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 11:32:46,547 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 11:32:51,018 INFO  [http-nio-7013-exec-1] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 11:32:51,018 INFO  [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 11:32:51,019 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 11:32:51,025 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 11:32:51,026 INFO  [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 8 ms
2020-06-05 11:32:51,032 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/publish?message=pompom%20cuk%20dancuk%20mbot", parameters={masked}
2020-06-05 11:32:51,034 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessageToKafkaTopic(String)
2020-06-05 11:32:51,047 INFO  [http-nio-7013-exec-1] com.spring.kafka.controller.KafkaController : send messege : pompom cuk dancuk mbot
2020-06-05 11:32:51,047 INFO  [http-nio-7013-exec-1] com.spring.kafka.service.Producer : sending message='pompom cuk dancuk mbot' to topic='foo.t'
2020-06-05 11:32:51,051 INFO  [http-nio-7013-exec-1] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 11:32:51,065 INFO  [http-nio-7013-exec-1] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 11:32:51,065 INFO  [http-nio-7013-exec-1] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 11:32:51,065 INFO  [http-nio-7013-exec-1] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591331571065
2020-06-05 11:32:51,073 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 11:32:51,103 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consumed message='pompom cuk dancuk mbot'
2020-06-05 11:32:51,104 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 11:32:51,104 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 11:32:51,105 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 11:33:19,220 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/publish?message=pompom%20cuk%20dancuk%20mbot", parameters={masked}
2020-06-05 11:33:19,221 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessageToKafkaTopic(String)
2020-06-05 11:33:19,221 INFO  [http-nio-7013-exec-3] com.spring.kafka.controller.KafkaController : send messege : pompom cuk dancuk mbot
2020-06-05 11:33:19,221 INFO  [http-nio-7013-exec-3] com.spring.kafka.service.Producer : sending message='pompom cuk dancuk mbot' to topic='foo.t'
2020-06-05 11:33:19,222 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 11:33:19,222 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 11:33:19,222 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 11:33:19,224 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consumed message='pompom cuk dancuk mbot'
2020-06-05 11:44:52,166 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 13556 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 11:44:52,169 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 11:44:52,965 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 11:44:52,971 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 11:44:52,971 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 11:44:53,032 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 11:44:53,032 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 11:44:53,032 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 827 ms
2020-06-05 11:44:53,208 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 11:44:53,217 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 11:44:53,255 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 3 mappings in 'requestMappingHandlerMapping'
2020-06-05 11:44:53,276 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 11:44:53,283 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 11:44:53,414 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 11:44:53,467 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 11:44:53,468 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 11:44:53,468 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591332293466
2020-06-05 11:44:53,470 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 11:44:53,472 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 11:44:53,490 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 11:44:53,499 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.659 seconds (JVM running for 2.575)
2020-06-05 11:44:53,762 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 11:44:53,763 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 11:44:53,765 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:44:53,774 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 11:44:53,774 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:44:53,778 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 33: {consumer-group_id-1-d7e3c0ba-ade9-4b2f-8c35-8ac85c9b5541=Assignment(partitions=[foo.t-0])}
2020-06-05 11:44:53,783 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 33
2020-06-05 11:44:53,786 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 11:44:53,793 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=11, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 11:44:53,794 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 11:44:57,204 INFO  [http-nio-7013-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 11:44:57,204 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 11:44:57,204 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 11:44:57,208 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 11:44:57,209 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 4 ms
2020-06-05 11:44:57,217 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/publish?message=pompom%20cuk%20dancuk%20mbot", parameters={masked}
2020-06-05 11:44:57,219 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessageToKafkaTopic(String)
2020-06-05 11:44:57,233 INFO  [http-nio-7013-exec-2] com.spring.kafka.controller.KafkaController : send message = 'pompom cuk dancuk mbot'  
2020-06-05 11:44:57,233 INFO  [http-nio-7013-exec-2] com.spring.kafka.service.Producer : sending message = 'pompom cuk dancuk mbot' to topic='foo.t'
2020-06-05 11:44:57,237 INFO  [http-nio-7013-exec-2] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 11:44:57,250 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 11:44:57,251 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 11:44:57,251 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591332297250
2020-06-05 11:44:57,257 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 11:44:57,288 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 11:44:57,288 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 11:44:57,289 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 11:45:01,518 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consumed message = 'pompom cuk dancuk mbot'
2020-06-05 11:57:25,631 INFO  [kafka-coordinator-heartbeat-thread | group_id] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-06-05 11:57:25,684 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.FetchSessionHandler : [Consumer clientId=consumer-group_id-1, groupId=group_id] Error sending fetch request (sessionId=1773316842, epoch=214) to node 0: {}.
org.apache.kafka.common.errors.DisconnectException: null
2020-06-05 11:57:25,694 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 11:57:25,726 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Attempt to heartbeat failed for since member id consumer-group_id-1-d7e3c0ba-ade9-4b2f-8c35-8ac85c9b5541 is not valid.
2020-06-05 11:57:25,727 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2020-06-05 11:57:25,727 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Lost previously assigned partitions foo.t-0
2020-06-05 11:57:25,727 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions lost: [foo.t-0]
2020-06-05 11:57:25,728 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions revoked: [foo.t-0]
2020-06-05 11:57:25,728 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:57:25,754 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 11:57:25,754 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 11:57:26,215 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 35: {consumer-group_id-1-5a5ff7f2-efd1-4654-8dcb-01a687e6a1a0=Assignment(partitions=[foo.t-0])}
2020-06-05 11:57:26,221 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 35
2020-06-05 11:57:26,221 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 11:57:26,222 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 11:57:26,223 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 13:11:06,523 INFO  [kafka-coordinator-heartbeat-thread | group_id] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-06-05 13:11:06,530 INFO  [kafka-coordinator-heartbeat-thread | group_id] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 13:11:06,530 INFO  [kafka-coordinator-heartbeat-thread | group_id] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
2020-06-05 13:11:07,034 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 13:11:08,620 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Attempt to heartbeat failed for since member id consumer-group_id-1-5a5ff7f2-efd1-4654-8dcb-01a687e6a1a0 is not valid.
2020-06-05 13:11:08,621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2020-06-05 13:11:08,621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Lost previously assigned partitions foo.t-0
2020-06-05 13:11:08,621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions lost: [foo.t-0]
2020-06-05 13:11:08,621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions revoked: [foo.t-0]
2020-06-05 13:11:08,621 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 13:11:08,623 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 13:11:08,623 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 13:11:08,720 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 37: {consumer-group_id-1-115883ef-5c50-4e30-b838-425146c7c050=Assignment(partitions=[foo.t-0])}
2020-06-05 13:11:08,743 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 37
2020-06-05 13:11:08,743 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 13:11:08,745 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 13:11:09,048 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 14:03:30,284 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 17176 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 14:03:30,289 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 14:03:31,098 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 14:03:31,105 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 14:03:31,106 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 14:03:31,168 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 14:03:31,169 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 14:03:31,169 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 840 ms
2020-06-05 14:03:31,352 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 14:03:31,362 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 14:03:31,400 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 14:03:31,422 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 14:03:31,428 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 14:03:31,555 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:03:31,610 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:03:31,611 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:03:31,611 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591340611609
2020-06-05 14:03:31,614 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 14:03:31,615 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:03:31,632 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 14:03:31,643 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.931 seconds (JVM running for 3.208)
2020-06-05 14:03:31,889 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:03:31,890 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:03:31,892 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:03:31,902 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:03:31,902 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:03:31,909 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 39: {consumer-group_id-1-73e9d048-b75a-4260-b87b-1cd3cb94c670=Assignment(partitions=[foo.t-0])}
2020-06-05 14:03:31,918 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 39
2020-06-05 14:03:31,921 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 14:03:31,929 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 14:03:31,930 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 14:03:49,920 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 4812 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 14:03:49,924 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 14:03:50,732 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 14:03:50,738 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 14:03:50,738 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 14:03:50,798 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 14:03:50,799 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 14:03:50,799 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 839 ms
2020-06-05 14:03:50,974 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 14:03:50,982 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 14:03:51,021 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 14:03:51,043 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 14:03:51,050 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 14:03:51,175 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:03:51,228 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:03:51,229 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:03:51,230 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591340631227
2020-06-05 14:03:51,232 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 14:03:51,234 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:03:51,253 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 14:03:51,260 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.669 seconds (JVM running for 2.602)
2020-06-05 14:03:51,509 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:03:51,511 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:03:51,513 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:03:51,522 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:03:51,522 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:04:23,712 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 6880 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 14:04:23,717 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 14:04:24,545 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 14:04:24,552 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 14:04:24,553 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 14:04:24,612 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 14:04:24,612 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 14:04:24,612 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 860 ms
2020-06-05 14:04:24,787 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 14:04:24,795 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 14:04:24,834 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 14:04:24,856 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 14:04:24,864 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 14:04:24,993 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:04:25,045 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:04:25,046 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:04:25,046 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591340665044
2020-06-05 14:04:25,048 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 14:04:25,050 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:04:25,068 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 14:04:25,076 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.691 seconds (JVM running for 2.634)
2020-06-05 14:04:25,322 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:04:25,324 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:04:25,326 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:04:25,335 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:04:25,336 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:04:25,340 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 42: {consumer-group_id-1-fcc5e914-e462-4317-8711-d7edf5b7c205=Assignment(partitions=[foo.t-0])}
2020-06-05 14:04:25,345 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 42
2020-06-05 14:04:25,348 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 14:04:25,355 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 14:04:25,356 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 14:05:28,053 INFO  [http-nio-7013-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 14:05:28,053 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 14:05:28,053 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 14:05:28,058 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 14:05:28,058 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 5 ms
2020-06-05 14:05:28,064 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj?id=1&name=ars&age=30", parameters={masked}
2020-06-05 14:05:28,067 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 14:05:28,088 WARN  [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver : Resolved [org.springframework.http.converter.HttpMessageNotReadableException: Required request body is missing: public void com.spring.kafka.controller.KafkaController.sendMessage(com.spring.kafka.model.User) throws java.lang.Exception]
2020-06-05 14:05:28,088 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed 400 BAD_REQUEST
2020-06-05 14:05:28,093 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : "ERROR" dispatch for POST "/error?id=1&name=ars&age=30", parameters={masked}
2020-06-05 14:05:28,095 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController#error(HttpServletRequest)
2020-06-05 14:05:28,110 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 14:05:28,111 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Writing [{timestamp=Fri Jun 05 14:05:28 ICT 2020, status=400, error=Bad Request, message=, path=/kafka/produc (truncated)...]
2020-06-05 14:05:28,146 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Exiting from "ERROR" dispatch, status 400
2020-06-05 14:06:22,357 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={masked}
2020-06-05 14:06:22,359 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 14:06:22,361 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod : Could not resolve parameter [0] in public void com.spring.kafka.controller.KafkaController.sendMessage(com.spring.kafka.model.User) throws java.lang.Exception: Content type 'multipart/form-data;boundary=--------------------------331495370339848536719163;charset=UTF-8' not supported
2020-06-05 14:06:22,362 WARN  [http-nio-7013-exec-4] org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.HttpMediaTypeNotSupportedException: Content type 'multipart/form-data;boundary=--------------------------331495370339848536719163;charset=UTF-8' not supported]
2020-06-05 14:06:22,363 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.DispatcherServlet : Completed 415 UNSUPPORTED_MEDIA_TYPE
2020-06-05 14:06:22,364 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.DispatcherServlet : "ERROR" dispatch for POST "/error", parameters={masked}
2020-06-05 14:06:22,364 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController#error(HttpServletRequest)
2020-06-05 14:06:22,365 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 14:06:22,365 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Writing [{timestamp=Fri Jun 05 14:06:22 ICT 2020, status=415, error=Unsupported Media Type, message=, path=/k (truncated)...]
2020-06-05 14:06:22,366 DEBUG [http-nio-7013-exec-4] org.springframework.web.servlet.DispatcherServlet : Exiting from "ERROR" dispatch, status 415
2020-06-05 14:07:36,958 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={masked}
2020-06-05 14:07:36,958 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 14:07:36,960 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod : Could not resolve parameter [0] in public void com.spring.kafka.controller.KafkaController.sendMessage(com.spring.kafka.model.User) throws java.lang.Exception: Content type 'application/x-www-form-urlencoded;charset=UTF-8' not supported
2020-06-05 14:07:36,960 WARN  [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.HttpMediaTypeNotSupportedException: Content type 'application/x-www-form-urlencoded;charset=UTF-8' not supported]
2020-06-05 14:07:36,961 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.DispatcherServlet : Completed 415 UNSUPPORTED_MEDIA_TYPE
2020-06-05 14:07:36,961 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.DispatcherServlet : "ERROR" dispatch for POST "/error", parameters={masked}
2020-06-05 14:07:36,961 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController#error(HttpServletRequest)
2020-06-05 14:07:36,962 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 14:07:36,962 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Writing [{timestamp=Fri Jun 05 14:07:36 ICT 2020, status=415, error=Unsupported Media Type, message=, path=/k (truncated)...]
2020-06-05 14:07:36,963 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.DispatcherServlet : Exiting from "ERROR" dispatch, status 415
2020-06-05 14:08:28,142 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={masked}
2020-06-05 14:08:28,142 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 14:08:28,143 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod : Could not resolve parameter [0] in public void com.spring.kafka.controller.KafkaController.sendMessage(com.spring.kafka.model.User) throws java.lang.Exception: Content type 'multipart/form-data;boundary=--------------------------080652057271991936625534;charset=UTF-8' not supported
2020-06-05 14:08:28,143 WARN  [http-nio-7013-exec-8] org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver : Resolved [org.springframework.web.HttpMediaTypeNotSupportedException: Content type 'multipart/form-data;boundary=--------------------------080652057271991936625534;charset=UTF-8' not supported]
2020-06-05 14:08:28,143 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.DispatcherServlet : Completed 415 UNSUPPORTED_MEDIA_TYPE
2020-06-05 14:08:28,143 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.DispatcherServlet : "ERROR" dispatch for POST "/error", parameters={masked}
2020-06-05 14:08:28,144 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to org.springframework.boot.autoconfigure.web.servlet.error.BasicErrorController#error(HttpServletRequest)
2020-06-05 14:08:28,144 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 14:08:28,145 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Writing [{timestamp=Fri Jun 05 14:08:28 ICT 2020, status=415, error=Unsupported Media Type, message=, path=/k (truncated)...]
2020-06-05 14:08:28,145 DEBUG [http-nio-7013-exec-8] org.springframework.web.servlet.DispatcherServlet : Exiting from "ERROR" dispatch, status 415
2020-06-05 14:11:12,715 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 14:11:12,716 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 14:11:12,746 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@69aef1ae]
2020-06-05 14:11:29,188 INFO  [http-nio-7013-exec-1] com.spring.kafka.controller.KafkaController : Send message = 'com.spring.kafka.model.User@69aef1ae'
2020-06-05 14:12:26,916 INFO  [http-nio-7013-exec-1] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":1}'
2020-06-05 14:12:36,632 INFO  [http-nio-7013-exec-1] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 14:12:36,652 INFO  [http-nio-7013-exec-1] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:12:36,654 INFO  [http-nio-7013-exec-1] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:12:36,654 INFO  [http-nio-7013-exec-1] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591341156652
2020-06-05 14:12:36,660 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:12:36,673 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 14:12:36,674 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 14:12:36,674 DEBUG [http-nio-7013-exec-1] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 14:12:47,205 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consumed message = '{"id":1,"name":"ars","age":1}'
2020-06-05 14:39:07,208 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 21328 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 14:39:07,211 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 14:39:08,075 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 14:39:08,081 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 14:39:08,081 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 14:39:08,141 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 14:39:08,141 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 14:39:08,141 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 895 ms
2020-06-05 14:39:08,317 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 14:39:08,325 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 14:39:08,366 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 14:39:08,387 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 14:39:08,394 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 14:39:08,532 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:39:08,587 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:39:08,588 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:39:08,588 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342748586
2020-06-05 14:39:08,591 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 14:39:08,593 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:39:08,597 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:39:08,605 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:39:08,605 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:39:08,605 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342748605
2020-06-05 14:39:08,605 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-2, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 14:39:08,605 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:39:08,619 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 14:39:08,629 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.752 seconds (JVM running for 2.689)
2020-06-05 14:39:08,872 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:39:08,872 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-2, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:39:08,873 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:39:08,873 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:39:08,875 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:39:08,875 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 14:39:08,883 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:39:08,883 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:39:08,883 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 14:39:08,884 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:39:17,856 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 23168 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 14:39:17,861 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 14:39:18,669 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 14:39:18,676 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 14:39:18,677 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 14:39:18,737 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 14:39:18,738 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 14:39:18,738 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 836 ms
2020-06-05 14:39:18,924 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 14:39:18,938 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 14:39:18,977 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 14:39:18,997 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 14:39:19,004 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 14:39:19,135 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:39:19,188 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:39:19,189 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:39:19,189 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342759186
2020-06-05 14:39:19,191 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 14:39:19,193 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:39:19,198 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:39:19,205 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:39:19,205 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:39:19,205 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342759205
2020-06-05 14:39:19,205 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-2, groupId=group_id] Subscribed to topic(s): obj.c
2020-06-05 14:39:19,205 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:39:19,220 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 14:39:19,227 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.703 seconds (JVM running for 2.608)
2020-06-05 14:39:19,478 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:39:19,479 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:39:19,481 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:39:19,490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:39:19,490 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:39:19,498 WARN  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.NetworkClient : [Consumer clientId=consumer-group_id-2, groupId=group_id] Error while fetching metadata with correlation id 2 : {obj.c=LEADER_NOT_AVAILABLE}
2020-06-05 14:39:19,499 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-2, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:39:19,499 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:39:19,500 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 14:39:19,504 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:39:19,504 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 14:39:21,968 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 44: {consumer-group_id-2-b707a8db-4405-4474-8b88-eeee042890e9=Assignment(partitions=[obj.c-0]), consumer-group_id-1-34e2a0e6-d357-4b51-84bf-3bb5ab283f7a=Assignment(partitions=[foo.t-0])}
2020-06-05 14:39:21,972 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully joined group with generation 44
2020-06-05 14:39:21,972 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 44
2020-06-05 14:39:21,977 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Adding newly assigned partitions: obj.c-0
2020-06-05 14:39:21,977 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 14:39:21,985 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Found no committed offset for partition obj.c-0
2020-06-05 14:39:21,986 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 14:39:21,986 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 14:39:21,992 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.SubscriptionState : [Consumer clientId=consumer-group_id-2, groupId=group_id] Resetting offset for partition obj.c-0 to offset 0.
2020-06-05 14:39:21,992 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [obj.c-0]
2020-06-05 14:39:31,354 INFO  [http-nio-7013-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 14:39:31,354 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 14:39:31,354 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 14:39:31,358 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 14:39:31,358 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 4 ms
2020-06-05 14:39:31,369 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 14:39:31,371 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 14:39:31,435 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@77c75ccc]
2020-06-05 14:39:34,618 INFO  [http-nio-7013-exec-2] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 14:39:39,795 INFO  [http-nio-7013-exec-2] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":1}'
2020-06-05 14:39:39,800 INFO  [http-nio-7013-exec-2] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 14:39:39,813 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:39:39,814 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:39:39,814 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342779813
2020-06-05 14:39:39,820 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:39:39,835 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 14:39:39,837 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 14:39:39,839 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 14:41:55,974 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 13712 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 14:41:55,978 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 14:41:56,789 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 14:41:56,796 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 14:41:56,796 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 14:41:56,857 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 14:41:56,857 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 14:41:56,857 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 843 ms
2020-06-05 14:41:57,036 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 14:41:57,045 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 14:41:57,087 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 14:41:57,118 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 14:41:57,124 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 14:41:57,246 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:41:57,299 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:41:57,300 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:41:57,300 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342917298
2020-06-05 14:41:57,302 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): obj.c
2020-06-05 14:41:57,304 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:41:57,309 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 14:41:57,315 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:41:57,315 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:41:57,315 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342917315
2020-06-05 14:41:57,315 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-2, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 14:41:57,316 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 14:41:57,330 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 14:41:57,338 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.689 seconds (JVM running for 2.612)
2020-06-05 14:41:57,581 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:41:57,581 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-2, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:41:57,582 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:41:57,582 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 14:41:57,584 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 14:41:57,584 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:41:57,593 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:41:57,593 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 14:41:57,593 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 14:41:57,593 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 14:41:57,600 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 46: {consumer-group_id-1-6047e86a-6f38-43e2-8b6f-9f3b6b4545e8=Assignment(partitions=[obj.c-0]), consumer-group_id-2-7c056343-25e0-4614-96a2-74429e42395f=Assignment(partitions=[foo.t-0])}
2020-06-05 14:41:57,603 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully joined group with generation 46
2020-06-05 14:41:57,603 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 46
2020-06-05 14:41:57,606 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: obj.c-0
2020-06-05 14:41:57,606 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 14:41:57,612 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Found no committed offset for partition obj.c-0
2020-06-05 14:41:57,613 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 14:41:57,614 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 14:41:57,617 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.SubscriptionState : [Consumer clientId=consumer-group_id-1, groupId=group_id] Resetting offset for partition obj.c-0 to offset 0.
2020-06-05 14:41:57,618 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [obj.c-0]
2020-06-05 14:42:01,128 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '1'
2020-06-05 14:42:12,727 INFO  [http-nio-7013-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 14:42:12,727 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 14:42:12,728 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 14:42:12,732 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 14:42:12,732 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 5 ms
2020-06-05 14:42:12,739 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 14:42:12,742 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 14:42:12,764 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@331050d8]
2020-06-05 14:42:15,122 INFO  [http-nio-7013-exec-2] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 14:42:48,481 INFO  [http-nio-7013-exec-2] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":30}'
2020-06-05 14:42:48,485 INFO  [http-nio-7013-exec-2] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 14:42:48,805 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 14:42:48,806 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 14:42:48,806 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591342968805
2020-06-05 14:42:48,814 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 14:42:48,830 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 14:42:48,831 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 14:42:48,832 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 14:42:51,100 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '30'
2020-06-05 15:32:50,941 DEBUG [http-nio-7013-exec-5] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 15:32:50,942 DEBUG [http-nio-7013-exec-5] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 15:32:50,943 DEBUG [http-nio-7013-exec-5] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@6acb5773]
2020-06-05 15:32:55,906 INFO  [http-nio-7013-exec-5] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 15:32:56,651 INFO  [http-nio-7013-exec-5] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":31}'
2020-06-05 15:32:56,657 DEBUG [http-nio-7013-exec-5] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 15:32:56,658 DEBUG [http-nio-7013-exec-5] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 15:32:56,658 DEBUG [http-nio-7013-exec-5] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 15:32:57,849 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '31'
2020-06-05 15:33:11,581 DEBUG [http-nio-7013-exec-6] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 15:33:11,582 DEBUG [http-nio-7013-exec-6] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 15:33:11,583 DEBUG [http-nio-7013-exec-6] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@909f06f]
2020-06-05 15:33:20,517 INFO  [http-nio-7013-exec-6] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 15:33:21,537 INFO  [http-nio-7013-exec-6] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":31}'
2020-06-05 15:33:21,539 DEBUG [http-nio-7013-exec-6] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 15:33:21,540 DEBUG [http-nio-7013-exec-6] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 15:33:21,540 DEBUG [http-nio-7013-exec-6] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 15:33:23,144 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '31'
2020-06-05 15:33:40,153 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 15:33:40,154 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 15:33:40,154 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@52623328]
2020-06-05 15:33:49,052 INFO  [http-nio-7013-exec-7] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 15:33:50,259 INFO  [http-nio-7013-exec-7] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":31}'
2020-06-05 15:33:50,260 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 15:33:50,261 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 15:33:50,261 DEBUG [http-nio-7013-exec-7] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 15:33:58,117 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '31'
2020-06-05 15:36:40,203 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 16636 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 15:36:40,208 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 15:36:41,001 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 15:36:41,008 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 15:36:41,009 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 15:36:41,067 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 15:36:41,067 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 15:36:41,067 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 824 ms
2020-06-05 15:36:41,243 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 15:36:41,252 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 15:36:41,291 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 15:36:41,313 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 15:36:41,319 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 15:36:41,449 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 15:36:41,502 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:36:41,502 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:36:41,502 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346201501
2020-06-05 15:36:41,504 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 15:36:41,506 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 15:36:41,510 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 15:36:41,517 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:36:41,517 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:36:41,517 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346201517
2020-06-05 15:36:41,517 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-2, groupId=group_id] Subscribed to topic(s): obj.c
2020-06-05 15:36:41,518 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 15:36:41,531 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 15:36:41,539 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.659 seconds (JVM running for 2.741)
2020-06-05 15:36:41,789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:36:41,789 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-2, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:36:41,790 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 15:36:41,790 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 15:36:41,792 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 15:36:41,792 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 15:36:41,801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 15:36:41,801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 15:36:41,801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 15:36:41,801 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 15:36:41,811 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 48: {consumer-group_id-1-1e2da6fd-d81e-4fe1-a1b5-8471642e373a=Assignment(partitions=[foo.t-0]), consumer-group_id-2-272f2c9c-d3d2-470c-bb2b-050aff426ff1=Assignment(partitions=[obj.c-0])}
2020-06-05 15:36:41,815 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 48
2020-06-05 15:36:41,815 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully joined group with generation 48
2020-06-05 15:36:41,817 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Adding newly assigned partitions: obj.c-0
2020-06-05 15:36:41,817 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 15:36:41,825 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Setting offset for partition obj.c-0 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 15:36:41,825 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 15:36:41,826 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [obj.c-0]
2020-06-05 15:36:41,826 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 15:36:52,126 INFO  [http-nio-7013-exec-3] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 15:36:52,126 INFO  [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 15:36:52,127 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 15:36:52,131 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 15:36:52,131 INFO  [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 4 ms
2020-06-05 15:36:52,137 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 15:36:52,140 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 15:36:52,199 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@7ca7c14b]
2020-06-05 15:36:58,254 INFO  [http-nio-7013-exec-3] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 15:36:59,510 INFO  [http-nio-7013-exec-3] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":31}'
2020-06-05 15:36:59,514 INFO  [http-nio-7013-exec-3] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 15:36:59,528 INFO  [http-nio-7013-exec-3] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:36:59,528 INFO  [http-nio-7013-exec-3] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:36:59,529 INFO  [http-nio-7013-exec-3] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346219528
2020-06-05 15:36:59,535 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:36:59,553 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Using 'application/json', given [*/*] and supported [application/json, application/*+json, application/json, application/*+json]
2020-06-05 15:36:59,553 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Nothing to write: null body
2020-06-05 15:36:59,554 DEBUG [http-nio-7013-exec-3] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 15:37:09,549 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '31'
2020-06-05 15:38:37,279 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 3896 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 15:38:37,283 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 15:38:38,079 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 15:38:38,086 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 15:38:38,086 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 15:38:38,149 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 15:38:38,150 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 15:38:38,150 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 830 ms
2020-06-05 15:38:38,328 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 15:38:38,336 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 15:38:38,378 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 15:38:38,400 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 15:38:38,406 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 15:38:38,537 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 15:38:38,591 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:38:38,592 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:38:38,592 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346318590
2020-06-05 15:38:38,594 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 15:38:38,596 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 15:38:38,601 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 15:38:38,607 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:38:38,607 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:38:38,607 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346318607
2020-06-05 15:38:38,607 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-2, groupId=group_id] Subscribed to topic(s): obj.c
2020-06-05 15:38:38,607 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 15:38:38,619 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 15:38:38,625 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.683 seconds (JVM running for 2.611)
2020-06-05 15:38:38,871 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-2, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:38:38,871 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:38:38,872 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 15:38:38,872 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 15:38:38,874 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 15:38:38,874 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 15:38:38,883 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 15:38:38,883 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 15:38:38,884 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 15:38:38,884 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 15:38:42,504 INFO  [http-nio-7013-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 15:38:42,504 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 15:38:42,504 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 15:38:42,511 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 15:38:42,511 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 7 ms
2020-06-05 15:38:42,520 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 15:38:42,524 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 15:38:42,608 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@36c98a13]
2020-06-05 15:38:42,614 INFO  [http-nio-7013-exec-2] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 15:38:42,941 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Finished assignment for group at generation 49: {consumer-group_id-2-669c7031-becb-49ee-b8fb-9eca0359945f=Assignment(partitions=[obj.c-0]), consumer-group_id-1-5026dcd2-e976-457b-a54b-1c8f2a933dbf=Assignment(partitions=[foo.t-0])}
2020-06-05 15:38:42,944 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully joined group with generation 49
2020-06-05 15:38:42,944 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 49
2020-06-05 15:38:42,947 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Adding newly assigned partitions: obj.c-0
2020-06-05 15:38:42,947 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 15:38:42,955 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 15:38:42,955 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Setting offset for partition obj.c-0 to the committed offset FetchPosition{offset=6, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 15:38:42,956 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 15:38:42,956 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [obj.c-0]
2020-06-05 15:38:46,069 INFO  [http-nio-7013-exec-2] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":31}'
2020-06-05 15:38:46,072 INFO  [http-nio-7013-exec-2] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 15:38:46,085 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:38:46,085 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:38:46,085 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346326085
2020-06-05 15:38:46,091 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:38:46,108 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Using 'text/plain', given [*/*] and supported [text/plain, */*, text/plain, */*, application/json, application/*+json, application/json, application/*+json]
2020-06-05 15:38:46,108 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Writing ["OK"]
2020-06-05 15:38:46,114 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 15:38:46,963 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '31'
2020-06-05 15:40:20,092 INFO  [main] com.spring.kafka.KafkaApplication : Starting KafkaApplication on LAPTOP-402KR1H4 with PID 548 (D:\Git Alfa Eclipse\kafka\target\classes started by Aris in D:\Git Alfa Eclipse\kafka)
2020-06-05 15:40:20,096 INFO  [main] com.spring.kafka.KafkaApplication : No active profile set, falling back to default profiles: default
2020-06-05 15:40:20,887 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 7013 (http)
2020-06-05 15:40:20,893 INFO  [main] org.apache.catalina.core.StandardService : Starting service [Tomcat]
2020-06-05 15:40:20,894 INFO  [main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-05 15:40:20,953 INFO  [main] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext
2020-06-05 15:40:20,953 DEBUG [main] org.springframework.web.context.ContextLoader : Published root WebApplicationContext as ServletContext attribute with name [org.springframework.web.context.WebApplicationContext.ROOT]
2020-06-05 15:40:20,953 INFO  [main] org.springframework.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 821 ms
2020-06-05 15:40:21,131 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-05 15:40:21,141 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter : ControllerAdvice beans: 0 @ModelAttribute, 0 @InitBinder, 1 RequestBodyAdvice, 1 ResponseBodyAdvice
2020-06-05 15:40:21,179 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : 4 mappings in 'requestMappingHandlerMapping'
2020-06-05 15:40:21,208 DEBUG [main] org.springframework.web.servlet.handler.SimpleUrlHandlerMapping : Patterns [/webjars/**, /**] in 'resourceHandlerMapping'
2020-06-05 15:40:21,215 DEBUG [main] org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver : ControllerAdvice beans: 0 @ExceptionHandler, 1 ResponseBodyAdvice
2020-06-05 15:40:21,331 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 15:40:21,384 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:40:21,385 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:40:21,385 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346421382
2020-06-05 15:40:21,387 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-1, groupId=group_id] Subscribed to topic(s): obj.c
2020-06-05 15:40:21,389 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 15:40:21,395 INFO  [main] org.apache.kafka.clients.consumer.ConsumerConfig : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = group_id
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

2020-06-05 15:40:21,402 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:40:21,402 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:40:21,402 INFO  [main] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346421402
2020-06-05 15:40:21,403 INFO  [main] org.apache.kafka.clients.consumer.KafkaConsumer : [Consumer clientId=consumer-group_id-2, groupId=group_id] Subscribed to topic(s): foo.t
2020-06-05 15:40:21,403 INFO  [main] org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler : Initializing ExecutorService
2020-06-05 15:40:21,418 INFO  [main] org.springframework.boot.web.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 7013 (http) with context path ''
2020-06-05 15:40:21,425 INFO  [main] com.spring.kafka.KafkaApplication : Started KafkaApplication in 1.657 seconds (JVM running for 2.557)
2020-06-05 15:40:21,658 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-1, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:40:21,658 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.Metadata : [Consumer clientId=consumer-group_id-2, groupId=group_id] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:40:21,659 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 15:40:21,659 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Discovered group coordinator LAPTOP-402KR1H4:9092 (id: 2147483647 rack: null)
2020-06-05 15:40:21,661 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 15:40:21,661 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 15:40:21,670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 15:40:21,670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-05 15:40:21,670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] (Re-)joining group
2020-06-05 15:40:21,670 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] (Re-)joining group
2020-06-05 15:40:25,983 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Finished assignment for group at generation 50: {consumer-group_id-2-a08ab31f-f956-4f67-ba79-288a06e1e357=Assignment(partitions=[foo.t-0]), consumer-group_id-1-ff3c4707-98c4-41a9-afca-a74e148ac7cf=Assignment(partitions=[obj.c-0])}
2020-06-05 15:40:25,986 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Successfully joined group with generation 50
2020-06-05 15:40:25,986 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.AbstractCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Successfully joined group with generation 50
2020-06-05 15:40:25,992 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Adding newly assigned partitions: foo.t-0
2020-06-05 15:40:25,992 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Adding newly assigned partitions: obj.c-0
2020-06-05 15:40:26,001 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-2, groupId=group_id] Setting offset for partition foo.t-0 to the committed offset FetchPosition{offset=13, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 15:40:26,001 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.consumer.internals.ConsumerCoordinator : [Consumer clientId=consumer-group_id-1, groupId=group_id] Setting offset for partition obj.c-0 to the committed offset FetchPosition{offset=7, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[LAPTOP-402KR1H4:9092 (id: 0 rack: null)], epoch=0}}
2020-06-05 15:40:26,002 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [obj.c-0]
2020-06-05 15:40:26,002 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] org.springframework.kafka.listener.KafkaMessageListenerContainer : group_id: partitions assigned: [foo.t-0]
2020-06-05 15:40:26,217 INFO  [http-nio-7013-exec-2] org.apache.catalina.core.ContainerBase.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-05 15:40:26,217 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'
2020-06-05 15:40:26,217 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Detected StandardServletMultipartResolver
2020-06-05 15:40:26,223 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : enableLoggingRequestDetails='false': request parameters and headers will be masked to prevent unsafe logging of potentially sensitive data
2020-06-05 15:40:26,223 INFO  [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed initialization in 6 ms
2020-06-05 15:40:26,230 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : POST "/kafka/produceObj", parameters={}
2020-06-05 15:40:26,232 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping : Mapped to com.spring.kafka.controller.KafkaController#sendMessage(User)
2020-06-05 15:40:26,290 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor : Read "application/json;charset=UTF-8" to [com.spring.kafka.model.User@1c12d5b5]
2020-06-05 15:40:26,296 INFO  [http-nio-7013-exec-2] com.spring.kafka.controller.KafkaController : Send message object
2020-06-05 15:40:31,092 INFO  [http-nio-7013-exec-2] com.spring.kafka.service.Producer : Sending message = '{"id":1,"name":"ars","age":31}'
2020-06-05 15:40:31,097 INFO  [http-nio-7013-exec-2] org.apache.kafka.clients.producer.ProducerConfig : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-05 15:40:31,111 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka version: 2.5.0
2020-06-05 15:40:31,112 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka commitId: 66563e712b0b9f84
2020-06-05 15:40:31,112 INFO  [http-nio-7013-exec-2] org.apache.kafka.common.utils.AppInfoParser : Kafka startTimeMs: 1591346431111
2020-06-05 15:40:31,120 INFO  [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata : [Producer clientId=producer-1] Cluster ID: bq48pKVQSYGxS2IgLaZqug
2020-06-05 15:40:31,149 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Using 'text/plain', given [*/*] and supported [text/plain, */*, text/plain, */*, application/json, application/*+json, application/json, application/*+json]
2020-06-05 15:40:31,150 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.mvc.method.annotation.HttpEntityMethodProcessor : Writing ["OK"]
2020-06-05 15:40:31,160 DEBUG [http-nio-7013-exec-2] org.springframework.web.servlet.DispatcherServlet : Completed 200 OK
2020-06-05 15:40:31,952 INFO  [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] com.spring.kafka.service.Consumer : Consume message id = '1', name = 'ars', age = '31'
